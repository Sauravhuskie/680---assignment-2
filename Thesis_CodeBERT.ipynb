{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sauravhuskie/680---assignment-2/blob/main/Thesis_CodeBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "\n",
        "Models (CodeBERT): \n",
        "1. https://github.com/microsoft/CodeBERT\n",
        "2. https://github.com/microsoft/CodeBERT/tree/master/CodeBERT/code2nl\n",
        "\n",
        "Other Sources\n",
        "2. https://favtutor.com/blogs/print-list-python\n",
        "3. https://towardsdatascience.com/running-pytorch-on-tpu-a-bag-of-tricks-b6d0130bddd4\n",
        "4. https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=OApBOAe1fpH_\n",
        "\n",
        "Diff in Codes:\n",
        "1. difflib: http://pymotw.com/2/difflib/\n",
        "2. diff patch match: https://pypi.org/project/diff-match-patch/\n",
        "\n",
        "TPU Installation\n",
        "1. https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=vJZrkoejQhxK\n",
        "\n",
        "AST\n",
        "1. https://github.com/pombredanne/python-ast-visualizer/blob/master/astvisualizer.py\n",
        "\n",
        "2. https://github.com/lensvol/astboom\n",
        "\n",
        "Similar Products\n",
        "\n",
        "1. https://github.com/eth-sri/TFix\n",
        "2. https://github.com/fluidattacks/NIST-SARD-Test-Suites\n",
        "3. https://github.com/SySeVR/SySeVR\n",
        "\n",
        "References\n",
        "1. Code-Bert: https://arxiv.org/pdf/2002.08155.pdf\n",
        "\n",
        "2. Code Database: https://arxiv.org/ftp/arxiv/papers/2108/2108.04631.pdf\n",
        "\n",
        "3. SySeVR: https://github.com/SySeVR/SySeVR\n",
        "\n",
        "Data-Sources\n",
        "\n",
        "1. https://www.nist.gov/itl/ssd/software-quality-group/static-analysis-tool-exposition-sate-iv\n",
        "\n",
        "2. SARD:  https://www.nist.gov/itl/ssd/software-quality-group/software-assurance-reference-dataset-sard-manual\n",
        "\n",
        "\n",
        "Neural Network\n",
        "1. https://www.atmosera.com/blog/text-classification-with-neural-networks/#:~:text=The%20first%20hidden%20layer%20in,rather%20than%20a%20single%20integer.\n",
        "\n",
        "2. https://machinelearningmastery.com/develop-word-embedding-model-predicting-movie-review-sentiment/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mvw1YJDs1xb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting TPU Setup\n"
      ],
      "metadata": {
        "id": "P5MueiS_-jHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "metadata": {
        "id": "Q0EE91vR-q2e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZPASIFE-r_e",
        "outputId": "767bbf65-d5ee-4688-fb27-37ab16c85a0b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==1.11\n",
            "  Using cached https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl (152.9 MB)\n",
            "Requirement already satisfied: cloud-tpu-client==0.10 in /usr/local/lib/python3.7/dist-packages (0.10)\n",
            "Collecting torch==1.11.0\n",
            "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client==1.8.0 in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client==0.10) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.35.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.15.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.31.5)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (62.2.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2022.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (21.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.56.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (4.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2021.10.8)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0a0+git8d365ae\n",
            "    Uninstalling torch-1.11.0a0+git8d365ae:\n",
            "      Successfully uninstalled torch-1.11.0a0+git8d365ae\n",
            "Successfully installed torch-1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall torch torchvision --yes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_WH__ccvIw2",
        "outputId": "36f9cf35-91da-48e1-92e7-2749155433d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.11.0\n",
            "Uninstalling torch-1.11.0:\n",
            "  Successfully uninstalled torch-1.11.0\n",
            "Found existing installation: torchvision 0.13.0a0+7be2f55\n",
            "Uninstalling torchvision-0.13.0a0+7be2f55:\n",
            "  Successfully uninstalled torchvision-0.13.0a0+7be2f55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.11.0\n",
        "!pip install torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsLKUYMZtn_H",
        "outputId": "2e78c95f-b980-4ff7-8b18-83ed1f9ce002"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.11.0\n",
            "  Using cached torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (4.2.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Successfully installed torch-1.11.0\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (21.0 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision) (4.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERSION = \"1.11\"  #@param [\"1.11\", \"nightly\", \"20220315\"]  # or YYYYMMDD format\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION\n",
        "import os \n",
        "os.environ['LD_LIBRARY_PATH']='/usr/local/lib'\n",
        "!echo $LD_LIBRARY_PATH\n",
        "\n",
        "!sudo ln -s /usr/local/lib/libmkl_intel_lp64.so /usr/local/lib/libmkl_intel_lp64.so.1\n",
        "!sudo ln -s /usr/local/lib/libmkl_intel_thread.so /usr/local/lib/libmkl_intel_thread.so.1\n",
        "!sudo ln -s /usr/local/lib/libmkl_core.so /usr/local/lib/libmkl_core.so.1\n",
        "\n",
        "!ldconfig\n",
        "!ldd /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch.so"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hnt_swgsmAM",
        "outputId": "b5ec5168-ceac-4cd9-bc29-f06bd7a515f5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  6034  100  6034    0     0   120k      0 --:--:-- --:--:-- --:--:--  120k\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-1.11 ...\n",
            "Found existing installation: torch 1.11.0\n",
            "Uninstalling torch-1.11.0:\n",
            "  Successfully uninstalled torch-1.11.0\n",
            "Found existing installation: torchvision 0.12.0\n",
            "Uninstalling torchvision-0.12.0:\n",
            "  Successfully uninstalled torchvision-0.12.0\n",
            "Copying gs://tpu-pytorch/wheels/colab/torch-1.11-cp37-cp37m-linux_x86_64.whl...\n",
            "| [1 files][ 98.8 MiB/ 98.8 MiB]                                                \n",
            "Operation completed over 1 objects/98.8 MiB.                                     \n",
            "Done updating TPU runtime\n",
            "Copying gs://tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][145.8 MiB/145.8 MiB]                                                \n",
            "Operation completed over 1 objects/145.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/colab/torchvision-1.11-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  5.7 MiB/  5.7 MiB]                                                \n",
            "Operation completed over 1 objects/5.7 MiB.                                      \n",
            "Processing ./torch-1.11-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11) (4.2.0)\n",
            "Installing collected packages: torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 1.0.61 requires torchvision, which is not installed.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.11.0a0+git8d365ae which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.11.0a0+git8d365ae which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.11.0a0+git8d365ae\n",
            "Processing ./torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n",
            "torch-xla is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "Processing ./torchvision-1.11-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==1.11) (1.11.0a0+git8d365ae)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision==1.11) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==1.11) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision==1.11) (4.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==1.11) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==1.11) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==1.11) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==1.11) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision==1.11) (3.0.4)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.13.0a0+7be2f55\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "/usr/local/lib\n",
            "ln: failed to create symbolic link '/usr/local/lib/libmkl_intel_lp64.so.1': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libmkl_intel_thread.so.1': File exists\n",
            "ln: failed to create symbolic link '/usr/local/lib/libmkl_core.so.1': File exists\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "\tlinux-vdso.so.1 (0x00007ffc741fe000)\n",
            "\t/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4 (0x00007f673c6f4000)\n",
            "\tlibtorch_cpu.so => /usr/local/lib/python3.7/dist-packages/torch/lib/libtorch_cpu.so (0x00007f67335c0000)\n",
            "\tlibc10.so => /usr/local/lib/python3.7/dist-packages/torch/lib/libc10.so (0x00007f6733361000)\n",
            "\tlibmkl_intel_lp64.so.1 => /usr/local/lib/libmkl_intel_lp64.so.1 (0x00007f6732830000)\n",
            "\tlibmkl_intel_thread.so.1 => /usr/local/lib/libmkl_intel_thread.so.1 (0x00007f6730350000)\n",
            "\tlibmkl_core.so.1 => /usr/local/lib/libmkl_core.so.1 (0x00007f672c217000)\n",
            "\tlibomp.so.5 => /usr/lib/x86_64-linux-gnu/libomp.so.5 (0x00007f672bf62000)\n",
            "\tlibpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f672bd43000)\n",
            "\tlibm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f672b9a5000)\n",
            "\tlibdl.so.2 => /lib/x86_64-linux-gnu/libdl.so.2 (0x00007f672b7a1000)\n",
            "\tlibstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f672b418000)\n",
            "\tlibgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f672b200000)\n",
            "\tlibc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f672ae0f000)\n",
            "\tlibunwind.so.8 => /usr/lib/x86_64-linux-gnu/libunwind.so.8 (0x00007f672abf4000)\n",
            "\tlibrt.so.1 => /lib/x86_64-linux-gnu/librt.so.1 (0x00007f672a9ec000)\n",
            "\t/lib64/ld-linux-x86-64.so.2 (0x00007f673cb66000)\n",
            "\tliblzma.so.5 => /lib/x86_64-linux-gnu/liblzma.so.5 (0x00007f672a7c6000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports pytorch\n",
        "import torch\n",
        "\n",
        "# imports the torch_xla package\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "G9Wcw8YM-9T8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "233c9a64-6602-407c-c704-a260524048ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TPU has started up successfully with version pytorch-1.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
        "dev = xm.xla_device()\n",
        "t1 = torch.ones(3, 3, device = dev)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJUfo4g_wD1",
        "outputId": "1ec419e2-649a-49dd-e9c4-81c72bfbb9ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]], device='xla:1')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys9XV4YA2gEp",
        "outputId": "c78b6e12-4d76-440d-9b53-458418cec47d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor on the second Cloud TPU core\n",
        "dev2 = xm.xla_device(n=2, devkind='TPU')\n",
        "t2 = torch.zeros(3, 3, device = dev2)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-X2BqwQGj1F",
        "outputId": "d6b49780-86e8-4a24-b071-682c8a806cce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], device='xla:2')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kIREKrFG_M1",
        "outputId": "cbba57bf-82c5-4c0e-e7fe-05d0c65642e1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor on the second Cloud TPU core\n",
        "dev3 = xm.xla_device(n=3, devkind='TPU')\n",
        "t2 = torch.zeros(3, 3, device = dev3)\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUKlfmMDGt8l",
        "outputId": "36a0ce7a-686f-429b-a463-626ca0f3b4a0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]], device='xla:3')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v5BQh2IHCQO",
        "outputId": "cc96f5c4-d4a8-4e99-f2be-c798416bc5a1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xla:3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating NL - PL Pair"
      ],
      "metadata": {
        "id": "E8lkSNAN2OLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkDEgCjomdTk",
        "outputId": "8a7ce641-448b-4e45-8db6-e48f68940b3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L66mxSQAtK6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902c6b2d-303f-4f1b-db35-aab9b604ae54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaModel(\n",
              "  (embeddings): RobertaEmbeddings(\n",
              "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "    (token_type_embeddings): Embedding(1, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): RobertaEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): RobertaLayer(\n",
              "        (attention): RobertaAttention(\n",
              "          (self): RobertaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): RobertaSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): RobertaIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): RobertaOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): RobertaPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaConfig, RobertaModel\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = RobertaModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "model.to(dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyCtM9FNtTDl",
        "outputId": "b8c0dc1f-71a7-4f79-8dfa-93f3b6b8af1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['return', 'maximum', 'value']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
        "nl_tokens=tokenizer.tokenize(\"return maximum value\")\n",
        "nl_tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code_tokens=tokenizer.tokenize(\"def max(a,b): if a>b: return a else return b\")"
      ],
      "metadata": {
        "id": "oA1h80hGu2Ip"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nl_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_l4hTkJvCuQ",
        "outputId": "37b6c9c7-484a-48d9-d74b-f3001fc0bf68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['return', 'maximum', 'value']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]+code_tokens+[tokenizer.sep_token]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buxe7FhFu3ht",
        "outputId": "df3e57b7-2bb5-40ca-a5b2-93e81fdbab83"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'return',\n",
              " 'maximum',\n",
              " 'value',\n",
              " '</s>',\n",
              " 'def',\n",
              " 'max',\n",
              " '(',\n",
              " 'a',\n",
              " ',',\n",
              " 'b',\n",
              " '):',\n",
              " 'if',\n",
              " 'a',\n",
              " '>',\n",
              " 'b',\n",
              " ':',\n",
              " 'return',\n",
              " 'a',\n",
              " 'else',\n",
              " 'return',\n",
              " 'b',\n",
              " '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_ids=tokenizer.convert_tokens_to_ids(tokens)\n",
        "tvpairs = zip(tokens,tokens_ids)\n",
        "for i in tvpairs: \n",
        "  print (tuple(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_S97x9qvSwu",
        "outputId": "eb7347fa-2faa-4be0-c1d4-08be03a9e0a4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('<s>', 0)\n",
            "('return', 30921)\n",
            "('maximum', 4532)\n",
            "('value', 923)\n",
            "('</s>', 2)\n",
            "('def', 9232)\n",
            "('max', 19220)\n",
            "('(', 1640)\n",
            "('a', 102)\n",
            "(',', 6)\n",
            "('b', 428)\n",
            "('):', 3256)\n",
            "('if', 114)\n",
            "('a', 10)\n",
            "('>', 15698)\n",
            "('b', 428)\n",
            "(':', 35)\n",
            "('return', 671)\n",
            "('a', 10)\n",
            "('else', 1493)\n",
            "('return', 671)\n",
            "('b', 741)\n",
            "('</s>', 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_embeddings=model(torch.tensor(tokens_ids)[None,:])[0]\n",
        "context_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olun6OJtvc1Q",
        "outputId": "ceccc44d-e096-4fe3-b032-667c500317e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1423,  0.3766,  0.0443,  ..., -0.2513, -0.3099,  0.3183],\n",
              "         [-0.5739,  0.1333,  0.2314,  ..., -0.1240, -0.1219,  0.2033],\n",
              "         [-0.1579,  0.1335,  0.0291,  ...,  0.2340, -0.8801,  0.6216],\n",
              "         ...,\n",
              "         [-0.4042,  0.2284,  0.5241,  ..., -0.2046, -0.2419,  0.7031],\n",
              "         [-0.3894,  0.4603,  0.4797,  ..., -0.3335, -0.6049,  0.4730],\n",
              "         [-0.1433,  0.3785,  0.0450,  ..., -0.2527, -0.3121,  0.3207]]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaConfig, RobertaTokenizer, RobertaForMaskedLM, pipeline\n",
        "model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")"
      ],
      "metadata": {
        "id": "URhUuV3rwJCl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mask Prediction"
      ],
      "metadata": {
        "id": "JoTjTJfPBm1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "CODE = \"if (x <mask> not None) & (x>1)\"\n",
        "fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
        "outputs = fill_mask(CODE)\n"
      ],
      "metadata": {
        "id": "86RHiWTiwXLG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in outputs: print (\"missing token:\", i['token_str'], \" with probability\",float (i[\"score\"]) * 100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rj_5b_ByxZn",
        "outputId": "76fe8404-5ee1-4610-bc36-110298b0026f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing token: >  with probability 22.588132321834564 %\n",
            "missing token: <  with probability 17.550398409366608 %\n",
            "missing token: ==  with probability 14.48403149843216 %\n",
            "missing token: =  with probability 6.862775236368179 %\n",
            "missing token: is  with probability 6.072976812720299 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Patch Detection or Change in Code"
      ],
      "metadata": {
        "id": "31IrwG_OJbx2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## difflib: Use for texts"
      ],
      "metadata": {
        "id": "y5Y8x2MEY4Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text1 = \"\"\"Saurav Is a good boy\"\"\"\n",
        "text1_lines = text1.splitlines()\n",
        "\n",
        "text2 = \"\"\"Saurav is a bad boy \"\"\"\n",
        "text2_lines = text2.splitlines()"
      ],
      "metadata": {
        "id": "4pysheocJaq-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import difflib\n",
        "d = difflib.Differ()\n",
        "diff = d.compare(text1_lines, text2_lines)\n",
        "print ('\\n'.join(diff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgZPdz-7Xb4_",
        "outputId": "a74f86e1-f665-47c0-83a9-6773ceaba333"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Saurav Is a good boy\n",
            "?        ^    ^^^\n",
            "\n",
            "+ Saurav is a bad boy \n",
            "?        ^    ^^     +\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## diffUtils: Good for codes\n"
      ],
      "metadata": {
        "id": "GxUgTRjobpyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade setuptools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAojMnLFr-7t",
        "outputId": "764fb625-7031-48a1-8cd1-6883454a47b1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (62.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install diff-match-patch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1WsICJUqkS7",
        "outputId": "1106b401-f669-4404-9727-356e2755d22c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diff-match-patch in /usr/local/lib/python3.7/dist-packages (20200713)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Source = \"I am the very model of a modern Major-General.\"\n",
        "Update =\"I am the very model of a cartoon individual.matters?\""
      ],
      "metadata": {
        "id": "0O9jjNtl6DRU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diff_match_patch import diff_match_patch\n",
        "\n",
        "dmp = diff_match_patch()\n",
        "patches = dmp.patch_make(Source, Update)\n",
        "diff = dmp.patch_toText(patches)\n",
        "diff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "GotbhjAtbpgM",
        "outputId": "ad2403a2-f720-4f18-82e6-06d9c4a98b6d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@@ -22,25 +22,31 @@\\n f a \\n-modern Major-General.\\n+cartoon individual.matters?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diff_match_patch import diff_match_patch\n",
        "\n",
        "dmp = diff_match_patch()\n",
        "patches = dmp.patch_fromText(diff)\n",
        "new_text1, _ = dmp.patch_apply(patches, Source)\n"
      ],
      "metadata": {
        "id": "-azglivM8onx"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ubCnXd5-Qkh",
        "outputId": "342c0fdc-b9ec-4e86-a041-f06dbda33aa3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am the very model of a cartoon individual.matters?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##patch test"
      ],
      "metadata": {
        "id": "0boXKZAwBfWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "add = \"\"\" \n",
        "def add(a, b):\n",
        "  return a + b\n",
        "\"\"\"\n",
        "\n",
        "sub = \"\"\"\n",
        "def add(a,b):\n",
        "  return a - b\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "d-seBaNANJ0w"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codeB2G = \"\"\"\n",
        "package testcases.CWE191_Integer_Underflow.s05; \n",
        "import testcasesupport.*; \n",
        "  \n",
        "public class CWE191_Integer_Underflow__short_rand_predec_81_goodB2G extends CWE191_Integer_Underflow__short_rand_predec_81_base \n",
        "{ \n",
        "    public void action(short data ) throws Throwable \n",
        "    { \n",
        "  \n",
        "        /* FIX: Add a check to prevent an underflow from occurring */\n",
        "        if (data > Short.MIN_VALUE) \n",
        "        { \n",
        "            short result = (short)(--data); \n",
        "            IO.writeLine(\"result: \" + result); \n",
        "        } \n",
        "        else\n",
        "        { \n",
        "            IO.writeLine(\"data value is too small to decrement.\"); \n",
        "        } \n",
        "  \n",
        "    } \n",
        "} \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "F7luSO4W6LxP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "codeG2B = \"\"\"\n",
        "package testcases.CWE191_Integer_Underflow.s05; \n",
        "import testcasesupport.*; \n",
        "  \n",
        "public class CWE191_Integer_Underflow__short_rand_predec_81_goodG2B extends CWE191_Integer_Underflow__short_rand_predec_81_base \n",
        "{ \n",
        "    public void action(short data ) throws Throwable \n",
        "    { \n",
        "  \n",
        "        /* POTENTIAL FLAW: if data == Short.MIN_VALUE, this will overflow */\n",
        "        short result = (short)(--data); \n",
        "  \n",
        "        IO.writeLine(\"result: \" + result); \n",
        "  \n",
        "    } \n",
        "} \n",
        "} \n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hGu1EH-D7xGO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findPatch(Source, Update):\n",
        "  from diff_match_patch import diff_match_patch\n",
        "  tmpPatch = diff_match_patch()\n",
        "  tempPatches = dmp.patch_make(Source, Update)\n",
        "  diff = dmp.patch_toText(tempPatches)\n",
        "  tempPatches = dmp.patch_fromText(diff)\n",
        "  tempdiff = dmp.patch_toText(tempPatches)\n",
        "  print(tempdiff)\n",
        "\n",
        "def applyPatch(code,patch):\n",
        "  from diff_match_patch import diff_match_patch\n",
        "  dmp = diff_match_patch()\n",
        "  new_text1, _ = dmp.patch_apply(patch, code)\n",
        "  print(new_text1)\n",
        "\n"
      ],
      "metadata": {
        "id": "fdovj85zVEwL"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Block for two functions\n",
        "add2sub = findPatch(sub,add)\n",
        "applyPatch(add, add2sub)\n",
        "sub2add = findPatch(add,sub)\n",
        "applyPatch(sub, sub2add)\n"
      ],
      "metadata": {
        "id": "YRjeRqlbWnEL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1863e966-2bb1-4fab-ba34-c3883864752b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@@ -1,8 +1,9 @@\n",
            "+ \n",
            " %0Adef add\n",
            "@@ -5,16 +5,17 @@\n",
            " f add(a,\n",
            "+ \n",
            " b):%0A  re\n",
            "@@ -25,8 +25,8 @@\n",
            " n a \n",
            "--\n",
            "++\n",
            "  b%0A\n",
            "\n",
            " \n",
            "def add(a, b):\n",
            "  return a + b\n",
            "\n",
            "@@ -1,9 +1,8 @@\n",
            "- \n",
            " %0Adef add\n",
            "@@ -4,17 +4,16 @@\n",
            " f add(a,\n",
            "- \n",
            " b):%0A  re\n",
            "@@ -23,8 +23,8 @@\n",
            " n a \n",
            "-+\n",
            "+-\n",
            "  b%0A\n",
            "\n",
            "\n",
            "def add(a,b):\n",
            "  return a - b\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Block for two functions\n",
        "add2sub = findPatch(codeG2B,codeB2G)\n",
        "print(add2sub)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWY6MzKN8ecN",
        "outputId": "92545917-fdc3-45f6-d4a7-dc908d238709"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "@@ -141,11 +141,11 @@\n",
            " good\n",
            "-G2B\n",
            "+B2G\n",
            "  ext\n",
            "@@ -284,34 +284,85 @@\n",
            "  /* \n",
            "-POTENTIAL FLAW:\n",
            "+FIX: Add a check to prevent an underflow from occurring */%0A       \n",
            "  if \n",
            "+(\n",
            " data \n",
            "-==\n",
            "+%3E\n",
            "  Sho\n",
            "@@ -377,32 +377,26 @@\n",
            " ALUE\n",
            "-, this will overflow */%0A\n",
            "+) %0A        %7B %0A    \n",
            "     \n",
            "@@ -430,25 +430,26 @@\n",
            " --data); %0A  \n",
            "-%0A\n",
            "+  \n",
            "         IO.w\n",
            "@@ -486,16 +486,127 @@\n",
            "  %0A  \n",
            "+      %7D %0A        else%0A        %7B %0A            IO.writeLine(%22data value is too small to decrement.%22); %0A        %7D %0A  \n",
            " %0A    \n",
            "-%7D %0A\n",
            " %7D %0A%7D\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Data\n"
      ],
      "metadata": {
        "id": "SAqr0u65Yw91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "folder = r\"/content/drive/MyDrive/Thesis/CWE-078\"\n",
        "subfolders = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
        "dst = '/content/drive/MyDrive/Thesis/CWE-078'\n",
        "\n",
        "\n",
        "for sub in subfolders:\n",
        "    for f in os.listdir(sub):\n",
        "        src = os.path.join(sub, f)\n",
        "        dst = folder\n",
        "        if f.endswith('.cpp'):\n",
        "          shutil.move(src, dst)\n",
        "\n"
      ],
      "metadata": {
        "id": "JNOpL1c8BlpV"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "folder = r\"/content/drive/MyDrive/Thesis/CWE195\"\n",
        "subfolders = [f.path for f in os.scandir(folder) if f.is_dir()]\n",
        "dst = '/content/drive/MyDrive/Thesis/CWE195'\n",
        "\n",
        "\n",
        "for sub in subfolders:\n",
        "    for f in os.listdir(sub):\n",
        "        src = os.path.join(sub, f)\n",
        "        dst = folder\n",
        "        print (\"src: \",  src , \"dst: \",dst)\n",
        "        if f.endswith('.cpp'):\n",
        "          shutil.move(src, dst)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xf-Xy_tTv_e",
        "outputId": "676baf77-862f-4e2d-d570-2a199c32db23"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src:  /content/drive/MyDrive/Thesis/CWE195/206/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_74a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/206/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_74b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/205/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_73a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/205/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_73b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/204/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_72b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/204/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_72a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/191/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_43.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/187/CWE195_Signed_to_Unsigned_Conversion_Error__rand_malloc_33.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/165/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_74a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/165/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_74b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/164/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_73b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/164/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_73a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/163/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_72b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/163/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_72a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/150/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_43.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/146/CWE195_Signed_to_Unsigned_Conversion_Error__negative_malloc_33.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/124/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_74a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/124/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_74b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/123/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_73a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/123/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_73b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/122/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_72a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/122/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_72b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/109/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_43.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/105/CWE195_Signed_to_Unsigned_Conversion_Error__listen_socket_malloc_33.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/083/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_74b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/083/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_74a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/082/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_73a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/082/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_73b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/081/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_72a.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/081/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_72b.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/068/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_43.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/064/CWE195_Signed_to_Unsigned_Conversion_Error__fscanf_malloc_33.cpp dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/CWE-195/manifest-2022-05-11-23-50-48-f09tau.xml dst:  /content/drive/MyDrive/Thesis/CWE195\n",
            "src:  /content/drive/MyDrive/Thesis/CWE195/CWE-195/testcases dst:  /content/drive/MyDrive/Thesis/CWE195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Neural Network"
      ],
      "metadata": {
        "id": "dn7Ga8f3ff2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4OgrM6ydflsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Thesis_CodeBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Cim3xmKWPMU55sH34cGhrXFIn30DGuTK",
      "authorship_tag": "ABX9TyNVVbDc9JvV4YHZWF9poVdV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}